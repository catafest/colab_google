{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8UiAsHycDJuVZLi1ccvPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catafest/colab_google/blob/master/catafest_047.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple example how to use the RNN known as **recurrent neural networks**.\n",
        "\n",
        "*Recurrent neural networks RNN are a class of neural networks that is powerful for modeling sequence data such as time series or natural language*.\n",
        "\n",
        "You can read more on [wikipedia](https://en.wikipedia.org/wiki/Recurrent_neural_network).\n"
      ],
      "metadata": {
        "id": "wRxto6sJlmwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with the import step for default python packages."
      ],
      "metadata": {
        "id": "SPNzXZQ4l3bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n"
      ],
      "metadata": {
        "id": "MM_PQRhfkvlf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set the layers for this neural network."
      ],
      "metadata": {
        "id": "Txh_rM1_l_pD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "G3HchVMGkrrx"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "model = tf.keras.layers.SimpleRNN(\n",
        "    units,\n",
        "    activation=\"tanh\",\n",
        "    use_bias=True,\n",
        "    kernel_initializer=\"glorot_uniform\",\n",
        "    recurrent_initializer=\"orthogonal\",\n",
        "    bias_initializer=\"zeros\",\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    #**kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let run to create the *sequence_output*,and *final_state*."
      ],
      "metadata": {
        "id": "4yGJDCdimGzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
        "simple_rnn = tf.keras.layers.SimpleRNN(4)\n",
        "\n",
        "output = simple_rnn(inputs)\n",
        "\n",
        "simple_rnn = tf.keras.layers.SimpleRNN(\n",
        "    4, return_sequences=True, return_state=True)\n",
        "\n",
        "sequence_output, final_state = simple_rnn(inputs)"
      ],
      "metadata": {
        "id": "ZHO-dYs2k5Mj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the results:"
      ],
      "metadata": {
        "id": "dBQTQPpTmUkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **sequence output**, often denoted as sequence_output, refers to the output of the RNN at each time step of the input sequence.\n",
        "\n",
        "In a language model, for example, this could be the predicted probability distribution over the vocabulary for each word in the input sentence. For each time step, the RNN produces an output that might encode information about the current input and the previous hidden state. The sequence output is a sequence of vectors where each vector corresponds to the output at a specific time step."
      ],
      "metadata": {
        "id": "ifw8uMyrnO9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sequence output\",sequence_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZL5AWPBlKED",
        "outputId": "8815b64d-af48-4710-db1a-cd923d8337fa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence output tf.Tensor(\n",
            "[[[-0.7376058  -0.27154022  0.6412025   0.26495436]\n",
            "  [ 0.22019926 -0.8107417   0.11049154  0.3031098 ]\n",
            "  [-0.21552336 -0.89441246  0.41979998 -0.39929935]\n",
            "  ...\n",
            "  [-0.8941558  -0.06466898  0.7695777   0.2538306 ]\n",
            "  [-0.22761662 -0.0241184  -0.15276092  0.51853603]\n",
            "  [-0.46362072 -0.6313244   0.82171834  0.30747953]]\n",
            "\n",
            " [[-0.24525905 -0.63860756  0.6035213  -0.67934316]\n",
            "  [-0.6880303  -0.5356085  -0.47181994  0.08338848]\n",
            "  [-0.7095654  -0.68703586  0.8514794  -0.00812948]\n",
            "  ...\n",
            "  [-0.87407583 -0.6574199   0.15843143 -0.31284106]\n",
            "  [-0.756225   -0.31491488  0.41810307  0.6721497 ]\n",
            "  [ 0.33724123 -0.41116393  0.59464574  0.39817914]]\n",
            "\n",
            " [[-0.5042844   0.09277479  0.16040711  0.2612613 ]\n",
            "  [-0.43343642 -0.04361439  0.32401708  0.6387127 ]\n",
            "  [ 0.20247814  0.41225934  0.45709464  0.24618687]\n",
            "  ...\n",
            "  [-0.1482535   0.8050526  -0.33205914 -0.613595  ]\n",
            "  [-0.35629544  0.78723353  0.64315593 -0.41220254]\n",
            "  [-0.42882958  0.5449506   0.5090625  -0.07940085]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.51769525 -0.30558413  0.6133827  -0.38904688]\n",
            "  [-0.49253646 -0.44561884 -0.26460359  0.23270653]\n",
            "  [-0.5889975  -0.35348114  0.6999199   0.4502235 ]\n",
            "  ...\n",
            "  [-0.07317087  0.52820987 -0.1138266   0.10972025]\n",
            "  [-0.29946238  0.07433473  0.6407248   0.32646853]\n",
            "  [ 0.22253513 -0.21490209  0.35315934  0.30243295]]\n",
            "\n",
            " [[-0.1476479  -0.2351126   0.415734   -0.6106256 ]\n",
            "  [-0.7728904   0.35305727  0.18203059 -0.6318223 ]\n",
            "  [-0.47695354  0.7508917  -0.32482383  0.79012436]\n",
            "  ...\n",
            "  [-0.27594543  0.37049776  0.5828117   0.47804078]\n",
            "  [ 0.03259213  0.39954597  0.18382645  0.32729822]\n",
            "  [-0.5637516   0.4134722   0.8458863  -0.51209605]]\n",
            "\n",
            " [[-0.06928569 -0.33951876  0.4679708  -0.72550035]\n",
            "  [-0.8947554   0.13669452  0.43492135 -0.10100649]\n",
            "  [-0.31331834  0.4368381   0.28584927  0.2572102 ]\n",
            "  ...\n",
            "  [ 0.2902729   0.37953767  0.3564978   0.11327424]\n",
            "  [-0.31258747  0.5500347   0.3170183  -0.05793008]\n",
            "  [ 0.15669014  0.27319527 -0.08769    -0.13074872]]], shape=(32, 10, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **final state**, often referred to as final_state, is the hidden state of the RNN after processing the entire input sequence.\n",
        "\n",
        "It represents the summarization of information learned from the entire sequence. In a language model, this final state might encapsulate the understanding of the entire sentence. This state can be used as an initial state when processing subsequent sequences, which can be useful for tasks like generating text sequentially."
      ],
      "metadata": {
        "id": "-nza4gQxnS0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"final_state\",final_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zaxo3B5ldj7",
        "outputId": "d674d351-3d6c-432a-b962-4701ae7bd3e6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_state tf.Tensor(\n",
            "[[-0.46362072 -0.6313244   0.82171834  0.30747953]\n",
            " [ 0.33724123 -0.41116393  0.59464574  0.39817914]\n",
            " [-0.42882958  0.5449506   0.5090625  -0.07940085]\n",
            " [-0.88141346 -0.02122334  0.7353388   0.18726377]\n",
            " [-0.2506953  -0.38087377  0.11141878 -0.12674046]\n",
            " [-0.1683723   0.10109448  0.11104453 -0.06542716]\n",
            " [-0.09716203 -0.27717307  0.7385087  -0.46453968]\n",
            " [-0.52165544  0.7480989  -0.03952791  0.23496689]\n",
            " [ 0.25015426 -0.4475493   0.02783038 -0.35240418]\n",
            " [ 0.05104969 -0.72378385  0.09075148  0.14886816]\n",
            " [-0.37033442  0.15645869 -0.02744232 -0.01338587]\n",
            " [ 0.2573149  -0.9446309   0.47538492 -0.04427608]\n",
            " [ 0.5575325  -0.41781384 -0.4111579   0.05440567]\n",
            " [ 0.08964776 -0.1407861   0.82569563  0.5465532 ]\n",
            " [ 0.27345413 -0.28769118  0.545642   -0.01720521]\n",
            " [ 0.5370163  -0.92477083  0.37222436  0.42600414]\n",
            " [-0.45385018  0.32283455 -0.5329749   0.46791974]\n",
            " [-0.54584676 -0.8512721   0.6010319   0.01500216]\n",
            " [-0.05098296 -0.50335073  0.5520216  -0.21641147]\n",
            " [-0.16960579  0.00691974 -0.05509946  0.19668499]\n",
            " [-0.3649167  -0.37586108  0.5696679   0.05995648]\n",
            " [-0.314022   -0.38526955  0.5602608  -0.06557769]\n",
            " [ 0.5903545   0.33654657  0.51665837 -0.394862  ]\n",
            " [-0.12884863 -0.6305836  -0.39923152  0.12536882]\n",
            " [-0.7053751  -0.73595726 -0.7926982   0.282879  ]\n",
            " [-0.58467746 -0.41065466  0.33238488 -0.78533566]\n",
            " [ 0.22332205 -0.31142262  0.41134512  0.5126883 ]\n",
            " [ 0.04425809 -0.81104416  0.25450885 -0.08511186]\n",
            " [-0.42915884  0.11229286  0.19343217 -0.73390317]\n",
            " [ 0.22253513 -0.21490209  0.35315934  0.30243295]\n",
            " [-0.5637516   0.4134722   0.8458863  -0.51209605]\n",
            " [ 0.15669014  0.27319527 -0.08769    -0.13074872]], shape=(32, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w6hyeCoyp3Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sequence output shape:\", sequence_output.shape)\n",
        "print(\"Final state shape:\", final_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyVKp1iJp3ez",
        "outputId": "2222dcb9-ed92-482e-d15d-36b97852836b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence output shape: (32, 10, 4)\n",
            "Final state shape: (32, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the next steps will depend on the specific task you are working on."
      ],
      "metadata": {
        "id": "hYXQxPi7r3Z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "common scenarios:\n",
        "\n",
        "*Sequence Classification* - to make a prediction.\n",
        "\n",
        "*Sequence-to-Sequence Tasks* - to generating the target sequence step by step using techniques like beam search or sampling.\n",
        "\n",
        "*Language Modeling and Text Generation* - generate the next word or token in the sequence or to predict the next word's probabilities.\n",
        "\n",
        "*Transfer Learning* - for transfer learning to fine-tune the RNN.\n",
        "\n",
        "*Feature Extraction* - for downstream tasks."
      ],
      "metadata": {
        "id": "t6sOsU4kvQiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE : Depending on the scenario you are using, you must have appropriate settings, see these settings for *Sequence-to-Sequence Tasks*:\n",
        "\n",
        "`return_sequences=True, return_state=True`"
      ],
      "metadata": {
        "id": "CItnKT4CwF9N"
      }
    }
  ]
}