{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOKUQLwMnzSQ+gR7ClfPLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catafest/colab_google/blob/master/catafest_057.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NVCC use CUDA C/C++ source code and allows developers to write high-performance GPU-accelerated applications by leveraging the power of NVIDIA GPUs for parallel processing tasks.\n",
        "\n",
        "The CUDA C/C++ source code is similar with the basic C/C++ source code.\n",
        "\n",
        "Read more on [nvcc website](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html).\n",
        "\n",
        "Today I will show two tutorials: the cuda source code for NVCC and a simple testing source code for nvidia-smi tool - I see is not install in my colab but will works because I tested in the past. All of these will run over runtime and will see how can set and unassign this runtime."
      ],
      "metadata": {
        "id": "_NA1fjq6RUkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set  runtime to GPU"
      ],
      "metadata": {
        "id": "kLdKDAuGKi_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.accelerator = 'GPU'\n"
      ],
      "metadata": {
        "id": "idyDkjxvt-IW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set values from nvidia-smi, if this is install on the colab."
      ],
      "metadata": {
        "id": "-5HgHzJqKmCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_enabled = True #@param {type:\"boolean\"}\n",
        "optix_enabled = True #@param {type:\"boolean\"}\n",
        "cpu_enabled = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "LvpiqoHOs7p_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to install **nvidia-smi** in order to use the source code !"
      ],
      "metadata": {
        "id": "1yQk5NcXKMRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content\n",
        "\n",
        "# gpu = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader\n",
        "# print(\"Current GPU: \" + gpu[0])\n",
        "\n",
        "# if gpu[0] == \"Tesla K80\" and optix_enabled:\n",
        "#   print(\"OptiX disabled because of unsupported GPU\")\n",
        "#   optix_enabled = False"
      ],
      "metadata": {
        "id": "VPYMr9_H6Izd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the nvcc compiler version"
      ],
      "metadata": {
        "id": "X4UfyZRdKxUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn9lTDvDtf6z",
        "outputId": "55a60f98-8595-406f-d6bd-d2eb91931e66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nOhTDvQbK3Pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install nvcc4jupyter , se more on : https://github.com/andreinechaev/nvcc4jupyter"
      ],
      "metadata": {
        "id": "P1hXYok8K4sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdrSiVMOHkk2",
        "outputId": "efd95462-915b-4876-e477-ba21a2284c72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.1.0-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the extension ..."
      ],
      "metadata": {
        "id": "TZey72fCK_U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDUsa7UDJt5F",
        "outputId": "0568a5b4-6a60-4ee6-f7c8-15a432c806ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source files will be saved in \"/tmp/tmpr4nhqbuq\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use the cuda cell magic command to run a simple hello world program."
      ],
      "metadata": {
        "id": "n-BLw5yCL6-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"This is from CUDA\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkYzilRwMpo0",
        "outputId": "05a0fb4c-604b-4637-9e87-2c9086a24b9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is from CUDA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "\n",
        "void hello(){\n",
        "    std::cout << \"Hello from function\";\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    hello();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ1WiZYuJ5p5",
        "outputId": "c14d6617-1689-41e1-deb2-7bc917259de2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L0pf9evXLz0n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUhLTD4rtYdW",
        "outputId": "d4093ca2-cac4-4655-f7f6-ca136dc92d36"
      },
      "source": [
        "# Install locate\n",
        "!apt-get install locate\n",
        "\n",
        "# Update db\n",
        "!updatedb"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "locate is already the newest version (4.8.0-1ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I need to remove this part of code linked by *#include \"error_handling.h\"* because is a fast exemple and I don't find this library."
      ],
      "metadata": {
        "id": "qM2Lox1iQhrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "//#include \"error_handling.h\"\n",
        "\n",
        "const int DSIZE = 4096;\n",
        "const int block_size = 256;\n",
        "\n",
        "// vector add kernel: C = A + B\n",
        "__global__ void vadd(const float *A, const float *B, float *C, int ds){\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < ds) {\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n",
        "\n",
        "    // allocate space for vectors in host memory\n",
        "    h_A = new float[DSIZE];\n",
        "    h_B = new float[DSIZE];\n",
        "    h_C = new float[DSIZE];\n",
        "\n",
        "    // initialize vectors in host memory to random values (except for the\n",
        "    // result vector whose values do not matter as they will be overwritten)\n",
        "    for (int i = 0; i < DSIZE; i++) {\n",
        "        h_A[i] = rand()/(float)RAND_MAX;\n",
        "        h_B[i] = rand()/(float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // allocate space for vectors in device memory\n",
        "    cudaMalloc(&d_A, DSIZE*sizeof(float));\n",
        "    cudaMalloc(&d_B, DSIZE*sizeof(float));\n",
        "    cudaMalloc(&d_C, DSIZE*sizeof(float));\n",
        "    //cudaCheckErrors(\"cudaMalloc failure\"); // error checking\n",
        "\n",
        "    // copy vectors A and B from host to device:\n",
        "    cudaMemcpy(d_A, h_A, DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    //cudaCheckErrors(\"cudaMemcpy H2D failure\");\n",
        "\n",
        "    // launch the vector adding kernel\n",
        "    vadd<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_B, d_C, DSIZE);\n",
        "    //cudaCheckErrors(\"kernel launch failure\");\n",
        "\n",
        "    // wait for the kernel to finish execution\n",
        "    cudaDeviceSynchronize();\n",
        "    //cudaCheckErrors(\"kernel execution failure\");\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    //cudaCheckErrors(\"cudaMemcpy D2H failure\");\n",
        "\n",
        "    printf(\"A[0] = %f\\n\", h_A[0]);\n",
        "    printf(\"B[0] = %f\\n\", h_B[0]);\n",
        "    printf(\"C[0] = %f\\n\", h_C[0]);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OT1wv5QPxX6",
        "outputId": "3c3a3611-467d-419a-8163-e6457079df20"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A[0] = 0.840188\n",
            "B[0] = 0.394383\n",
            "C[0] = 0.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't don't find this library and I need to make a research. My time resource is limited."
      ],
      "metadata": {
        "id": "H9f83s2hQzX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!locate error_handling.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Cll376P-BR",
        "outputId": "48686b28-49ca-4f65-d943-42111d4fa533"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/include/boost/detail/winapi/error_handling.hpp\n",
            "/usr/include/boost/math/distributions/detail/common_error_handling.hpp\n",
            "/usr/include/boost/math/policies/error_handling.hpp\n",
            "/usr/include/boost/spirit/home/classic/error_handling.hpp\n",
            "/usr/include/boost/spirit/include/classic_error_handling.hpp\n",
            "/usr/include/boost/winapi/error_handling.hpp\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/ducc/src/ducc0/infra/error_handling.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last part is about disconnect runtime. I don't find a solution to switch and run from source code just only set and unassign."
      ],
      "metadata": {
        "id": "vFHty22RKeUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "pjYaAQVKyNPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}