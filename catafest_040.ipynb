{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catafest/colab_google/blob/master/catafest_040.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's Animov model has an aspect called \"text-to-video\", which refers to the ability to generate animated videos based on an input text.\n",
        "I used *animov_0_1_1_text_to_video *.\n",
        "I used with this query: \"A beautiful woman drinking her coffee on vacation.\" to create a video .\n",
        "You need to run and open into browser this: https://82ce1cc4443ec52df9.gradio.live/"
      ],
      "metadata": {
        "id": "gPlkR-DRkBXU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd6fuWqPjQqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1122d33-6891-401d-8dbb-a63cfd2ec6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'modelscope-text-to-video-synthesis-hf'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 106 (delta 60), reused 65 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 21.34 KiB | 10.67 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "/content/modelscope-text-to-video-synthesis-hf\n",
            "Collecting git+https://github.com/huggingface/diffusers (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-7e3nksvt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-7e3nksvt\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 51593da25aba44ed27d8680dcf0cfca4459f1e85\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.17.1 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.17.1-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.23.0 (from -r requirements.txt (line 3))\n",
            "  Downloading gradio-3.23.0-py3-none-any.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.13.3 (from -r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio[ffmpeg]==2.26.1 (from -r requirements.txt (line 5))\n",
            "  Downloading imageio-2.26.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.0 (from -r requirements.txt (line 6))\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1 (from -r requirements.txt (line 7))\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.27.2 (from -r requirements.txt (line 8))\n",
            "  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.17.1->-r requirements.txt (line 1)) (6.0)\n",
            "Collecting aiofiles (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Collecting httpx (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (1.10.9)\n",
            "Collecting pydub (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (2.27.1)\n",
            "Collecting semantic-version (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio==3.23.0->-r requirements.txt (line 3)) (4.6.3)\n",
            "Collecting uvicorn (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.13.3->-r requirements.txt (line 4)) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.13.3->-r requirements.txt (line 4)) (4.65.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]==2.26.1->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 6)) (3.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2->-r requirements.txt (line 8)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.2->-r requirements.txt (line 8))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 6)) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 6)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 6)) (16.0.6)\n",
            "Collecting importlib-metadata (from diffusers==0.18.0.dev0->-r requirements.txt (line 2))\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 3)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r requirements.txt (line 3)) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.23.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.23.0->-r requirements.txt (line 3)) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23.0->-r requirements.txt (line 3)) (1.3.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.23.0->-r requirements.txt (line 3)) (2023.5.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.23.0->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.23.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.18.0.dev0->-r requirements.txt (line 2)) (3.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 3)) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23.0->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.23.0->-r requirements.txt (line 3)) (1.26.16)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.23.0->-r requirements.txt (line 3)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn->gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0->-r requirements.txt (line 3)) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0->-r requirements.txt (line 3)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r requirements.txt (line 3))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio==3.23.0->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0->-r requirements.txt (line 3)) (1.1.1)\n",
            "Building wheels for collected packages: diffusers, ffmpy\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.18.0.dev0-py3-none-any.whl size=1247962 sha256=51578b96e62450145c07d322c8325cedc18767fea1e72b6611d7a64fa5cc0fb9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8xused3b/wheels/f7/7d/99/d361489e5762e3464b3811bc629e94cf5bf5ef44dd5c3c4d52\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=d8e183eaeaffc3da3271d099925bf9a7783a26f9a7cd1508096e62dee9102b1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built diffusers ffmpy\n",
            "Installing collected packages: tokenizers, pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, markdown-it-py, importlib-metadata, imageio, h11, aiofiles, uvicorn, starlette, nvidia-cusolver-cu11, nvidia-cudnn-cu11, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, transformers, httpx, fastapi, diffusers, gradio, torch, torchvision, accelerate\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.25.1\n",
            "    Uninstalling imageio-2.25.1:\n",
            "      Successfully uninstalled imageio-2.25.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.17.1 aiofiles-23.1.0 diffusers-0.18.0.dev0 fastapi-0.99.1 ffmpy-0.3.0 gradio-3.23.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.13.3 imageio-2.26.1 importlib-metadata-6.7.0 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 orjson-3.9.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 tokenizers-0.13.3 torch-2.0.0 torchvision-0.15.1 transformers-4.27.2 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3\n",
            "2023-07-06 18:56:36.571366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading (…)ain/model_index.json: 100% 384/384 [00:00<00:00, 2.26MB/s]\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "Downloading (…)okenizer_config.json: 100% 755/755 [00:00<00:00, 4.96MB/s]\n",
            "\n",
            "Downloading (…)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)23e/unet/config.json: 100% 727/727 [00:00<00:00, 3.66MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 3.64MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 465/465 [00:00<00:00, 4.16MB/s]\n",
            "\n",
            "\n",
            "Fetching 12 files:  17% 2/12 [00:00<00:01,  5.66it/s]\n",
            "\n",
            "\n",
            "Downloading (…)_encoder/config.json: 100% 609/609 [00:00<00:00, 4.16MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 6.75MB/s]\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 12.1MB/s]\n",
            "\n",
            "Downloading (…)123e/vae/config.json: 100% 636/636 [00:00<00:00, 4.05MB/s]\n",
            "\n",
            "Downloading pytorch_model.bin:   0% 0.00/681M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   0% 0.00/2.82G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   2% 10.5M/681M [00:00<00:53, 12.6MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:   3% 21.0M/681M [00:01<00:31, 20.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   0% 10.5M/2.82G [00:00<03:42, 12.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   6% 10.5M/167M [00:00<00:12, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  13% 21.0M/167M [00:01<00:06, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   5% 31.5M/681M [00:01<00:24, 26.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   1% 21.0M/2.82G [00:01<02:14, 20.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   1% 31.5M/2.82G [00:01<01:36, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  19% 31.5M/167M [00:01<00:04, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   6% 41.9M/681M [00:01<00:21, 29.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   1% 41.9M/2.82G [00:01<01:27, 31.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  25% 41.9M/167M [00:01<00:03, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   8% 52.4M/681M [00:01<00:19, 31.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   2% 52.4M/2.82G [00:01<01:14, 37.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   9% 62.9M/681M [00:02<00:16, 37.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  31% 52.4M/167M [00:01<00:03, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   2% 62.9M/2.82G [00:02<01:13, 37.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  38% 62.9M/167M [00:02<00:02, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  11% 73.4M/681M [00:02<00:16, 37.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   3% 73.4M/2.82G [00:02<01:13, 37.3MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  12% 83.9M/681M [00:02<00:16, 37.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  44% 73.4M/167M [00:02<00:02, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   3% 83.9M/2.82G [00:02<01:05, 41.5MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  14% 94.4M/681M [00:02<00:15, 37.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  50% 83.9M/167M [00:02<00:02, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   3% 94.4M/2.82G [00:02<01:07, 40.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  56% 94.4M/167M [00:02<00:01, 40.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  15% 105M/681M [00:03<00:15, 37.3MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   4% 105M/2.82G [00:03<01:08, 39.7MB/s] \u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  17% 115M/681M [00:03<00:13, 40.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  63% 105M/167M [00:03<00:01, 39.1MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   4% 115M/2.82G [00:03<01:03, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  69% 115M/167M [00:03<00:01, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  18% 126M/681M [00:03<00:13, 40.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   4% 126M/2.82G [00:03<01:05, 41.3MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  20% 136M/681M [00:03<00:12, 43.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  75% 126M/167M [00:03<00:01, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   5% 136M/2.82G [00:03<01:06, 40.2MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  22% 147M/681M [00:04<00:12, 41.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  81% 136M/167M [00:03<00:00, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   5% 147M/2.82G [00:04<01:02, 43.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  23% 157M/681M [00:04<00:12, 40.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  88% 147M/167M [00:04<00:00, 39.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   6% 157M/2.82G [00:04<01:19, 33.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  94% 157M/167M [00:05<00:00, 17.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   6% 168M/2.82G [00:05<02:20, 18.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  25% 168M/681M [00:06<00:31, 16.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin: 100% 167M/167M [00:05<00:00, 28.8MB/s]\n",
            "\n",
            "Downloading pytorch_model.bin:  26% 178M/681M [00:06<00:24, 20.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   7% 189M/2.82G [00:05<01:26, 30.3MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  29% 199M/681M [00:06<00:13, 34.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   7% 210M/2.82G [00:06<00:57, 45.7MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  31% 210M/681M [00:06<00:11, 40.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   8% 220M/2.82G [00:06<00:50, 51.2MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  32% 220M/681M [00:06<00:09, 47.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   8% 231M/2.82G [00:06<00:45, 56.5MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  34% 231M/681M [00:06<00:08, 53.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   9% 241M/2.82G [00:06<00:40, 63.2MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  35% 241M/681M [00:06<00:07, 60.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   9% 252M/2.82G [00:06<00:36, 70.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:   9% 262M/2.82G [00:06<00:40, 63.4MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  38% 262M/681M [00:07<00:06, 60.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  10% 273M/2.82G [00:07<00:46, 54.4MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  40% 273M/681M [00:07<00:07, 52.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  10% 283M/2.82G [00:07<00:48, 52.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  42% 283M/681M [00:07<00:07, 52.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  10% 294M/2.82G [00:07<00:53, 47.2MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  43% 294M/681M [00:07<00:08, 48.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  11% 304M/2.82G [00:07<00:56, 44.8MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  45% 304M/681M [00:08<00:08, 44.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  11% 315M/2.82G [00:08<00:54, 45.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  46% 315M/681M [00:08<00:08, 44.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  12% 325M/2.82G [00:08<00:56, 44.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  48% 325M/681M [00:08<00:08, 44.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  12% 336M/2.82G [00:08<00:54, 45.5MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  49% 336M/681M [00:08<00:08, 42.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  12% 346M/2.82G [00:08<00:57, 42.8MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  51% 346M/681M [00:09<00:07, 44.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  13% 357M/2.82G [00:09<00:59, 41.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  52% 357M/681M [00:09<00:07, 42.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  13% 367M/2.82G [00:09<00:55, 44.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  54% 367M/681M [00:09<00:07, 40.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  13% 377M/2.82G [00:09<00:58, 42.0MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  55% 377M/681M [00:09<00:06, 43.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  14% 388M/2.82G [00:09<00:58, 41.7MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  57% 388M/681M [00:10<00:10, 28.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  14% 398M/2.82G [00:10<01:38, 24.5MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  59% 398M/681M [00:10<00:09, 28.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  15% 419M/2.82G [00:10<00:59, 40.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  62% 419M/681M [00:11<00:05, 44.0MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  63% 430M/681M [00:11<00:05, 41.9MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  65% 440M/681M [00:11<00:05, 40.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  16% 440M/2.82G [00:11<01:04, 37.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  16% 451M/2.82G [00:11<00:59, 39.7MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  66% 451M/681M [00:11<00:05, 40.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  16% 461M/2.82G [00:11<01:00, 38.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  68% 461M/681M [00:12<00:05, 39.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  17% 472M/2.82G [00:12<01:00, 38.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  69% 472M/681M [00:12<00:05, 38.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  17% 482M/2.82G [00:12<00:56, 41.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  71% 482M/681M [00:12<00:05, 38.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  17% 493M/2.82G [00:12<00:57, 40.7MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  72% 493M/681M [00:13<00:04, 38.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  18% 503M/2.82G [00:12<00:53, 43.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  74% 503M/681M [00:13<00:04, 38.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  18% 514M/2.82G [00:13<00:57, 40.0MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  75% 514M/681M [00:13<00:04, 41.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  19% 524M/2.82G [00:13<00:56, 40.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  77% 524M/681M [00:13<00:03, 40.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  19% 535M/2.82G [00:13<00:57, 39.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  79% 535M/681M [00:14<00:03, 40.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  19% 545M/2.82G [00:13<00:53, 42.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  80% 545M/681M [00:14<00:03, 42.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  20% 556M/2.82G [00:14<00:55, 41.2MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  82% 556M/681M [00:14<00:03, 41.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  20% 566M/2.82G [00:14<00:56, 40.3MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  83% 566M/681M [00:14<00:02, 40.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  20% 577M/2.82G [00:14<00:52, 43.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  85% 577M/681M [00:15<00:02, 42.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  21% 587M/2.82G [00:14<00:54, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  21% 598M/2.82G [00:15<00:50, 44.4MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  86% 587M/681M [00:15<00:02, 37.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  22% 608M/2.82G [00:15<00:52, 42.5MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  88% 598M/681M [00:15<00:02, 34.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  22% 619M/2.82G [00:15<00:54, 40.7MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  89% 608M/681M [00:16<00:02, 33.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  22% 629M/2.82G [00:15<00:49, 44.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  91% 619M/681M [00:16<00:01, 33.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  23% 640M/2.82G [00:16<00:55, 39.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  23% 650M/2.82G [00:16<00:52, 41.4MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  92% 629M/681M [00:16<00:01, 34.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  23% 661M/2.82G [00:16<00:53, 40.1MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  94% 640M/681M [00:17<00:01, 32.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  24% 671M/2.82G [00:16<00:49, 43.4MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  95% 650M/681M [00:17<00:00, 34.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  24% 682M/2.82G [00:17<00:51, 41.5MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  97% 661M/681M [00:17<00:00, 32.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  25% 692M/2.82G [00:17<00:52, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  25% 703M/2.82G [00:17<00:48, 43.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  99% 671M/681M [00:17<00:00, 34.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  25% 713M/2.82G [00:17<00:50, 41.6MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin: 100% 681M/681M [00:18<00:00, 37.1MB/s]\n",
            "Fetching 12 files:  33% 4/12 [00:19<00:44,  5.58s/it]\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  26% 724M/2.82G [00:18<00:52, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  26% 734M/2.82G [00:18<00:47, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  26% 744M/2.82G [00:18<00:50, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  27% 755M/2.82G [00:18<00:51, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  27% 765M/2.82G [00:19<00:52, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  27% 776M/2.82G [00:19<00:52, 38.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  28% 786M/2.82G [00:19<00:48, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  28% 797M/2.82G [00:19<00:49, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  29% 807M/2.82G [00:20<00:50, 39.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  29% 818M/2.82G [00:20<00:46, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  29% 828M/2.82G [00:20<00:48, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  30% 839M/2.82G [00:20<00:44, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  30% 849M/2.82G [00:21<00:47, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  30% 860M/2.82G [00:21<00:48, 40.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  31% 870M/2.82G [00:21<00:44, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  31% 881M/2.82G [00:21<00:47, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  32% 891M/2.82G [00:22<00:48, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  32% 902M/2.82G [00:22<00:48, 39.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  32% 912M/2.82G [00:22<00:44, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  33% 923M/2.82G [00:22<00:46, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  33% 933M/2.82G [00:23<00:42, 44.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  33% 944M/2.82G [00:23<00:45, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  34% 954M/2.82G [00:23<00:46, 40.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  34% 965M/2.82G [00:24<00:47, 38.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  35% 975M/2.82G [00:24<00:47, 38.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  35% 986M/2.82G [00:24<00:47, 38.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  35% 996M/2.82G [00:24<00:43, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  36% 1.01G/2.82G [00:25<00:44, 40.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  36% 1.02G/2.82G [00:25<00:45, 39.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  36% 1.03G/2.82G [00:25<00:42, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  37% 1.04G/2.82G [00:25<00:43, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  37% 1.05G/2.82G [00:26<00:40, 44.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  38% 1.06G/2.82G [00:26<00:41, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  38% 1.07G/2.82G [00:26<00:42, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  38% 1.08G/2.82G [00:26<00:39, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  39% 1.09G/2.82G [00:27<00:41, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  39% 1.10G/2.82G [00:27<00:38, 44.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  39% 1.11G/2.82G [00:27<00:40, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  40% 1.12G/2.82G [00:27<00:41, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  40% 1.13G/2.82G [00:28<00:39, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  40% 1.14G/2.82G [00:28<00:40, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  41% 1.15G/2.82G [00:28<00:38, 43.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  41% 1.16G/2.82G [00:28<00:38, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  42% 1.17G/2.82G [00:29<00:39, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  42% 1.18G/2.82G [00:29<00:38, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  42% 1.20G/2.82G [00:29<00:38, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  43% 1.21G/2.82G [00:29<00:39, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  43% 1.22G/2.82G [00:29<00:37, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  43% 1.23G/2.82G [00:30<00:37, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  44% 1.24G/2.82G [00:30<00:36, 44.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  44% 1.25G/2.82G [00:30<00:36, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  45% 1.26G/2.82G [00:31<00:37, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  45% 1.27G/2.82G [00:31<00:35, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  45% 1.28G/2.82G [00:31<00:36, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  46% 1.29G/2.82G [00:31<00:35, 43.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  46% 1.30G/2.82G [00:31<00:36, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  46% 1.31G/2.82G [00:32<00:36, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  47% 1.32G/2.82G [00:32<00:34, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  47% 1.33G/2.82G [00:32<00:35, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  48% 1.34G/2.82G [00:33<00:37, 39.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  48% 1.35G/2.82G [00:33<00:33, 43.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  48% 1.36G/2.82G [00:33<00:34, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  49% 1.37G/2.82G [00:33<00:32, 44.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  49% 1.38G/2.82G [00:33<00:34, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  49% 1.39G/2.82G [00:34<00:36, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  50% 1.41G/2.82G [00:34<00:36, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  50% 1.42G/2.82G [00:34<00:36, 38.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  51% 1.43G/2.82G [00:35<00:33, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  51% 1.44G/2.82G [00:35<00:33, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  51% 1.45G/2.82G [00:35<00:35, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  52% 1.46G/2.82G [00:35<00:34, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  52% 1.47G/2.82G [00:36<00:31, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  52% 1.48G/2.82G [00:36<00:33, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  53% 1.49G/2.82G [00:36<00:31, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  53% 1.50G/2.82G [00:36<00:32, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  53% 1.51G/2.82G [00:37<00:32, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  54% 1.52G/2.82G [00:37<00:30, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  54% 1.53G/2.82G [00:37<00:31, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  55% 1.54G/2.82G [00:37<00:31, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  55% 1.55G/2.82G [00:38<00:29, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  55% 1.56G/2.82G [00:38<00:30, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  56% 1.57G/2.82G [00:38<00:30, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  56% 1.58G/2.82G [00:38<00:28, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  56% 1.59G/2.82G [00:39<00:33, 36.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  57% 1.60G/2.82G [00:39<00:32, 37.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  57% 1.61G/2.82G [00:39<00:31, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  58% 1.63G/2.82G [00:39<00:29, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  58% 1.64G/2.82G [00:40<00:29, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  58% 1.65G/2.82G [00:40<00:29, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  59% 1.66G/2.82G [00:40<00:27, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  59% 1.67G/2.82G [00:40<00:27, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  59% 1.68G/2.82G [00:41<00:26, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  60% 1.69G/2.82G [00:41<00:27, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  60% 1.70G/2.82G [00:41<00:27, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  61% 1.71G/2.82G [00:41<00:25, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  61% 1.72G/2.82G [00:42<00:25, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  61% 1.73G/2.82G [00:42<00:26, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  62% 1.74G/2.82G [00:42<00:25, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  62% 1.75G/2.82G [00:42<00:25, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  62% 1.76G/2.82G [00:43<00:24, 43.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  63% 1.77G/2.82G [00:43<00:25, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  63% 1.78G/2.82G [00:43<00:24, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  64% 1.79G/2.82G [00:43<00:23, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  64% 1.80G/2.82G [00:44<00:23, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  64% 1.81G/2.82G [00:44<00:24, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  65% 1.82G/2.82G [00:44<00:23, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  65% 1.84G/2.82G [00:44<00:23, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  65% 1.85G/2.82G [00:45<00:23, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  66% 1.86G/2.82G [00:45<00:22, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  66% 1.87G/2.82G [00:45<00:22, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  66% 1.88G/2.82G [00:45<00:21, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  67% 1.89G/2.82G [00:46<00:22, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  67% 1.90G/2.82G [00:46<00:22, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  68% 1.91G/2.82G [00:46<00:21, 43.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  68% 1.92G/2.82G [00:46<00:21, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  68% 1.93G/2.82G [00:47<00:21, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  69% 1.94G/2.82G [00:47<00:20, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  69% 1.95G/2.82G [00:47<00:20, 42.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  69% 1.96G/2.82G [00:47<00:21, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  70% 1.97G/2.82G [00:48<00:19, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  70% 1.98G/2.82G [00:48<00:19, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  71% 1.99G/2.82G [00:48<00:19, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  71% 2.00G/2.82G [00:48<00:19, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  71% 2.01G/2.82G [00:49<00:19, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  72% 2.02G/2.82G [00:49<00:18, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  72% 2.03G/2.82G [00:49<00:18, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  72% 2.04G/2.82G [00:49<00:17, 44.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  73% 2.06G/2.82G [00:50<00:17, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  73% 2.07G/2.82G [00:50<00:18, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  74% 2.08G/2.82G [00:50<00:16, 44.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  74% 2.09G/2.82G [00:50<00:17, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  74% 2.10G/2.82G [00:51<00:16, 45.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  75% 2.11G/2.82G [00:51<00:17, 42.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  75% 2.12G/2.82G [00:51<00:17, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  75% 2.13G/2.82G [00:51<00:15, 44.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  76% 2.14G/2.82G [00:52<00:16, 42.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  76% 2.15G/2.82G [00:52<00:16, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  77% 2.16G/2.82G [00:52<00:16, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  77% 2.17G/2.82G [00:52<00:15, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  77% 2.18G/2.82G [00:53<00:15, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  78% 2.19G/2.82G [00:53<00:15, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  78% 2.20G/2.82G [00:53<00:14, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  78% 2.21G/2.82G [00:53<00:14, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  79% 2.22G/2.82G [00:54<00:14, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  79% 2.23G/2.82G [00:54<00:13, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  79% 2.24G/2.82G [00:54<00:14, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  80% 2.25G/2.82G [00:54<00:13, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  80% 2.26G/2.82G [00:55<00:13, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  81% 2.28G/2.82G [00:55<00:12, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  81% 2.29G/2.82G [00:55<00:12, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  81% 2.30G/2.82G [00:55<00:12, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  82% 2.31G/2.82G [00:56<00:12, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  82% 2.32G/2.82G [00:56<00:11, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  82% 2.33G/2.82G [00:56<00:11, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  83% 2.34G/2.82G [00:56<00:11, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  83% 2.35G/2.82G [00:57<00:11, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  84% 2.36G/2.82G [00:57<00:10, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  84% 2.37G/2.82G [00:57<00:10, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  84% 2.38G/2.82G [00:57<00:11, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  85% 2.39G/2.82G [00:58<00:09, 43.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  85% 2.40G/2.82G [00:58<00:10, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  85% 2.41G/2.82G [00:58<00:10, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  86% 2.42G/2.82G [00:58<00:10, 39.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  86% 2.43G/2.82G [00:59<00:09, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  87% 2.44G/2.82G [00:59<00:09, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  87% 2.45G/2.82G [00:59<00:08, 44.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  87% 2.46G/2.82G [00:59<00:08, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  88% 2.47G/2.82G [01:00<00:08, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  88% 2.49G/2.82G [01:00<00:07, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  88% 2.50G/2.82G [01:00<00:07, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  89% 2.51G/2.82G [01:00<00:08, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  89% 2.52G/2.82G [01:01<00:07, 39.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  90% 2.53G/2.82G [01:01<00:06, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  90% 2.54G/2.82G [01:01<00:06, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  90% 2.55G/2.82G [01:01<00:06, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  91% 2.56G/2.82G [01:02<00:06, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  91% 2.57G/2.82G [01:02<00:06, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  91% 2.58G/2.82G [01:02<00:05, 44.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  92% 2.59G/2.82G [01:02<00:05, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  92% 2.60G/2.82G [01:03<00:05, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  92% 2.61G/2.82G [01:03<00:05, 40.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  93% 2.62G/2.82G [01:03<00:04, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  93% 2.63G/2.82G [01:03<00:05, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  94% 2.64G/2.82G [01:04<00:04, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  94% 2.65G/2.82G [01:04<00:04, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  94% 2.66G/2.82G [01:04<00:04, 38.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  95% 2.67G/2.82G [01:04<00:03, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  95% 2.68G/2.82G [01:05<00:03, 40.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  95% 2.69G/2.82G [01:05<00:03, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  96% 2.71G/2.82G [01:05<00:03, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  96% 2.72G/2.82G [01:06<00:02, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  97% 2.73G/2.82G [01:06<00:02, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  97% 2.74G/2.82G [01:06<00:02, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  97% 2.75G/2.82G [01:06<00:01, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  98% 2.76G/2.82G [01:08<00:03, 19.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin:  98% 2.78G/2.82G [01:09<00:02, 18.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)on_pytorch_model.bin: 100% 2.82G/2.82G [01:09<00:00, 40.6MB/s]\n",
            "Fetching 12 files: 100% 12/12 [01:10<00:00,  5.88s/it]\n",
            "Keyword arguments {'safety_checker': None} are not expected by TextToVideoSDPipeline and will be ignored.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://82ce1cc4443ec52df9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "100% 25/25 [00:22<00:00,  1.12it/s]\n",
            "100% 25/25 [00:19<00:00,  1.29it/s]\n",
            "100% 25/25 [00:19<00:00,  1.28it/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/modelscope-text-to-video-synthesis-hf\n",
        "%cd /content/modelscope-text-to-video-synthesis-hf\n",
        "!pip install -r requirements.txt\n",
        "!sed -i 's/text-to-video-ms-1.7b/animov-0.1.1/g' app.py\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}